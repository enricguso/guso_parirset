{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a87f39-cc16-4f75-ab21-0a467352eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import tqdm\n",
    "import scipy.signal as sig\n",
    "import time\n",
    "import numpy as np\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9065d-e062-42fc-8d5a-c28363b2cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavFolderDataset(Dataset,):\n",
    "    def __init__(self, main_path, mode, sample_rate=48000):\n",
    "        self.maxlen = 60000 #maximum IR lenght in samples\n",
    "        self.main_path = main_path\n",
    "        self.mode = mode\n",
    "        if mode == 'b1':\n",
    "            folders = ['b1_gp']\n",
    "        elif mode == 'd1':\n",
    "            folders = ['b1_gp', 'd1_original']\n",
    "        elif mode == 'd2':\n",
    "            folders = ['b1_gp', 'd1_original', 'd2_capsules']\n",
    "        elif mode == 'd3':\n",
    "            folders = ['b1_gp', 'd1_original', 'd2_capsules', 'd3_beamforming']\n",
    "        elif mode == 'd4':\n",
    "            folders = ['b1_gp', 'd1_original', 'd2_capsules', 'd3_beamforming', 'd4_permute']\n",
    "        elif mode == 'ob1':\n",
    "            folders = ['b1_gp']\n",
    "        elif mode == 'od1':\n",
    "            folders = ['d1_original']\n",
    "        elif mode == 'od2':\n",
    "            folders = ['d2_capsules']\n",
    "        elif mode == 'od3':\n",
    "            folders = ['d3_beamforming']\n",
    "        elif mode == 'od4':\n",
    "            folders = ['d4_permute']\n",
    "        else:\n",
    "            print('unspecified RIR dataset!')\n",
    "        \n",
    "        wav_files = []\n",
    "        for folder in folders:\n",
    "            files = os.listdir(os.path.join(main_path, folder))\n",
    "            for f in files:\n",
    "                if '.wav' in f:\n",
    "                    wav_files.append(os.path.join(os.path.join(main_path, folder), f))\n",
    "        self.wav_files = wav_files\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wav_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.wav_files[idx]\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "        if self.sample_rate and sr != self.sample_rate:\n",
    "            print('resampling RIR.')\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, self.sample_rate)\n",
    "            sr = self.sample_rate\n",
    "            \n",
    "        zeros_to_pad = self.maxlen - waveform.shape[1]\n",
    "        if zeros_to_pad > 0:\n",
    "            return torch.hstack((waveform, torch.zeros((2, zeros_to_pad))))\n",
    "        else:\n",
    "            return waveform[:, :self.maxlen]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b813e36-c127-44b5-a63c-29d0ca48ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/media/diskA/enric/parirset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5060c6-6eeb-4332-ba09-f79ae2ef59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(signal):\n",
    "    return torch.mean(signal**2)\n",
    "    \n",
    "def conv_torch(test_track, x):\n",
    "    #minibatch, channels, iW\n",
    "    batch_size = x.shape[0]\n",
    "    out = []\n",
    "    for i in range(batch_size):\n",
    "        left = torchaudio.functional.fftconvolve(\n",
    "            test_track[i, 0, :],\n",
    "            x[i, 0, :], 'same')\n",
    "        right = torchaudio.functional.fftconvolve(\n",
    "            test_track[i, 1, :],\n",
    "            x[i, 1, :], 'same')\n",
    "        \n",
    "        mix = torch.stack([left, right])\n",
    "        mix *= torch.sqrt(power(test_track) / power(mix)) #keep power the same as input audio\n",
    "        out.append(mix)\n",
    "    return torch.stack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f9c0d-20ee-4fe1-8e8f-94aa37fcfd56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def conv_scipy(test_track, x):\n",
    "    #if test_track.device != 'cpu':\n",
    "    #    test_track = test_track.detach().cpu().numpy()\n",
    "    #    x = x.detach().cpu().numpy()\n",
    "    #else:\n",
    "    #    test_track = test_track.numpy()\n",
    "    #    x = x.numpy()\n",
    "    batch_size = x.shape[0]\n",
    "    out = []\n",
    "    for i in range(batch_size):\n",
    "        left = sig.fftconvolve(test_track[i, 0, :], x[i, 0,:])\n",
    "        right = sig.fftconvolve(test_track[i, 1, :], x[i, 1,:])\n",
    "\n",
    "    return np.array(out) #torch.from_numpy(np.array(out)).to(\"cuda:1\")\n",
    "# TRY SCIPY CONV\n",
    "\n",
    "test_track, _ = torchaudio.load('test_track.wav')\n",
    "BS = 5\n",
    "dataset = WavFolderDataset(main_path, 'd1')\n",
    "loader = DataLoader(dataset, batch_size=BS, shuffle=False, drop_last=True)\n",
    "\n",
    "t1 = time.time()\n",
    "#test_track = test_track.to(\"cuda:1\")\n",
    "test_track = test_track.repeat(BS,1,1)\n",
    "test_track = test_track.numpy()\n",
    "\n",
    "for x in tqdm.tqdm(loader):\n",
    "    #x = x.to(\"cuda:1\")\n",
    "    _ = conv_scipy(test_track, x)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df9cc2-037a-4063-b828-ebd43720cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUCH FASTER PYTORCH CONV\n",
    "test_track, _ = torchaudio.load('test_track.wav')\n",
    "\n",
    "t1 = time.time()\n",
    "test_track = test_track.to(\"cuda:1\")\n",
    "test_track = test_track.repeat(BS,1,1)\n",
    "\n",
    "for x in tqdm.tqdm(loader):\n",
    "    x = x.to(\"cuda:1\")\n",
    "    out2 = conv_torch(test_track, x)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b1d43-c993-4e08-a4bf-cd9a029a481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test_track, _ = torchaudio.load('test_track.wav')\n",
    "\n",
    "t1 = time.time()\n",
    "test_track = test_track.to(\"cuda:1\")\n",
    "test_track = test_track.repeat(BS,1,1)\n",
    "\n",
    "for x in tqdm.tqdm(loader):\n",
    "    x = x.to(\"cuda:1\")\n",
    "    out3 = conv_torch_batch(test_track, x)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5896d-0a06-4a66-b20e-68fd9b15d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539a701-08e1-4002-b74a-47c3cf4d90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(out2[0].cpu().numpy(), rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61c4cd-c032-47b0-9d9f-6fd2435f1732",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(out2[3].cpu().numpy(), rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d44bb-d55c-4aad-a819-4bb8d12ea997",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(out2[4].cpu().numpy(), rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384433c4-5aaa-403d-9b49-34db96c2d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(out2[0].cpu().numpy(), rate=48000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scnet",
   "language": "python",
   "name": "scnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
